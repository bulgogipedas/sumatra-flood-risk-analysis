{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŒ´ðŸŒŠ SawitFlood Lab - Exploratory Data Analysis\n",
    "\n",
    "**Analisis Keterkaitan Deforestasi Kelapa Sawit dan Risiko Banjir di Sumatra**\n",
    "\n",
    "Notebook ini melakukan eksplorasi data awal untuk:\n",
    "1. Memahami distribusi dan karakteristik data\n",
    "2. Mengidentifikasi pola dan korelasi\n",
    "3. Mendeteksi outlier dan data quality issues\n",
    "4. Visualisasi spasial dan temporal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "processed_dir = PROJECT_ROOT / \"data\" / \"processed\"\n",
    "\n",
    "gpkg_path = processed_dir / \"analysis_dataset.gpkg\"\n",
    "parquet_path = processed_dir / \"analysis_dataset.parquet\"\n",
    "csv_path = processed_dir / \"analysis_dataset.csv\"\n",
    "\n",
    "gdf, df = None, None\n",
    "\n",
    "if gpkg_path.exists():\n",
    "    gdf = gpd.read_file(gpkg_path)\n",
    "    df = gdf.drop(columns=[\"geometry\"])\n",
    "    print(f\"Loaded GeoPackage: {gpkg_path}\")\n",
    "elif parquet_path.exists():\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    print(f\"Loaded Parquet: {parquet_path}\")\n",
    "elif csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(f\"Loaded CSV: {csv_path}\")\n",
    "else:\n",
    "    print(\"No data found. Run data pipeline first.\")\n",
    "    from src.data.build_dataset import DatasetBuilder\n",
    "\n",
    "    builder = DatasetBuilder()\n",
    "    gdf = builder.build_analysis_dataset()\n",
    "    df = gdf.drop(columns=[\"geometry\"])\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values and data types\n",
    "print(\"Dataset Info:\")\n",
    "print(\"=\" * 50)\n",
    "print(df.info())\n",
    "\n",
    "# Missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "if missing.sum() > 0:\n",
    "    print(\"\\nColumns with missing values:\")\n",
    "    print(missing[missing > 0])\n",
    "else:\n",
    "    print(\"\\nâœ… No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descriptive Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns statistics\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution Visualizations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of key features\n",
    "key_features = [\n",
    "    \"forest_loss_cumulative_pct\",\n",
    "    \"palm_oil_pct\",\n",
    "    \"rainfall_annual_mean_mm\",\n",
    "    \"risk_probability\",\n",
    "]\n",
    "available_features = [f for f in key_features if f in df.columns]\n",
    "\n",
    "if available_features:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, feature in enumerate(available_features[:4]):\n",
    "        sns.histplot(df[feature], kde=True, ax=axes[i], color=\"steelblue\")\n",
    "        axes[i].set_title(f\"Distribution of {feature}\")\n",
    "        axes[i].axvline(df[feature].mean(), color=\"red\", linestyle=\"--\", label=\"Mean\")\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Correlation Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numeric_df = df[numeric_cols].dropna()\n",
    "if len(numeric_df.columns) > 1:\n",
    "    corr_matrix = numeric_df.corr()\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(\n",
    "        corr_matrix, mask=mask, annot=True, cmap=\"RdYlGn_r\", center=0, fmt=\".2f\", linewidths=0.5\n",
    "    )\n",
    "    plt.title(\"Feature Correlation Matrix\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "Based on this EDA, proceed to:\n",
    "1. **Model Training**: `02_modeling_risk.ipynb`\n",
    "2. **SHAP Analysis**: `03_xai_shap_analysis.ipynb`\n",
    "\n",
    "---\n",
    "*SawitFlood Lab - Environmental Risk Analysis*\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
